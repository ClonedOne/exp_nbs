{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from art import config\n",
    "from art.utils import load_dataset\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "from art.data_generators import KerasDataGenerator\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix randomness\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# training parameters\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "dataset_subsample = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 28, 28, 1) (5000, 28, 28, 1) (30000, 10) (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset('mnist')\n",
    "\n",
    "# Subsample the data set for speed\n",
    "_, x_train_s = train_test_split(x_train, test_size=dataset_subsample, random_state=seed, stratify=y_train)\n",
    "_, x_test_s = train_test_split(x_test, test_size=dataset_subsample, random_state=seed, stratify=y_test)\n",
    "_, y_train_s = train_test_split(y_train, test_size=dataset_subsample, random_state=seed, stratify=y_train)\n",
    "_, y_test_s = train_test_split(y_test, test_size=dataset_subsample, random_state=seed, stratify=y_test)\n",
    "\n",
    "# labels as integers\n",
    "y_test_s_labels = np.argmax(y_test_s, axis=-1)\n",
    "\n",
    "print(x_train_s.shape, x_test_s.shape, y_train_s.shape, y_test_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 363us/sample - loss: 0.1651 - accuracy: 0.9528\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 358us/sample - loss: 0.0484 - accuracy: 0.9845\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 351us/sample - loss: 0.0300 - accuracy: 0.9902\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 11s 355us/sample - loss: 0.0206 - accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 350us/sample - loss: 0.0193 - accuracy: 0.9938\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 362us/sample - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 11s 356us/sample - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 355us/sample - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 353us/sample - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 351us/sample - loss: 0.0067 - accuracy: 0.9983\n",
      "Accuracy on clean testing data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98580   0.99184   0.98881       490\n",
      "           1    0.98261   0.99647   0.98949       567\n",
      "           2    0.98649   0.99031   0.98839       516\n",
      "           3    0.99008   0.98812   0.98910       505\n",
      "           4    0.98776   0.98574   0.98675       491\n",
      "           5    0.97333   0.98206   0.97768       446\n",
      "           6    0.98337   0.98747   0.98542       479\n",
      "           7    0.98630   0.98054   0.98341       514\n",
      "           8    0.99374   0.97741   0.98551       487\n",
      "           9    0.98597   0.97426   0.98008       505\n",
      "\n",
      "    accuracy                        0.98560      5000\n",
      "   macro avg    0.98554   0.98542   0.98546      5000\n",
      "weighted avg    0.98563   0.98560   0.98559      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = build_model(input_shape=(28, 28, 1), num_classes=10)\n",
    "# model.fit(x_train_s, y_train_s, epochs=10)\n",
    "# safety_pred = np.argmax(model.predict(x_test_s), axis=-1)\n",
    "# print('Accuracy on clean testing data')\n",
    "# print(classification_report(y_test_s_labels, safety_pred, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,389,386\n",
      "Trainable params: 2,389,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape=(28, 28, 1), num_classes=10)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Wrappers for ART\n",
    "classifier = KerasClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d505c4b2e3b4a10a988e36c6b9aff4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Precompute adv samples', max=1.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e508a9de4594ccc896f1e5e87f50ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Adversarial training epochs', max=391.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giorgioseveri/.virtualenvs/maax/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/giorgioseveri/.virtualenvs/maax/lib/python3.8/site-packages/art/estimators/classification/keras.py:517: Model.fit_generator (from tensorflow.python.keras.engine.training_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create adversarial trainer and perform adversarial training\n",
    "trainer = AdversarialTrainerMadryPGD(\n",
    "    classifier,\n",
    "#     nb_epochs=n_epochs\n",
    ")\n",
    "trainer.fit(x_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean testing data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       490\n",
      "           1    0.07227   0.07584   0.07401       567\n",
      "           2    0.00000   0.00000   0.00000       516\n",
      "           3    0.00000   0.00000   0.00000       505\n",
      "           4    0.00000   0.00000   0.00000       491\n",
      "           5    0.00000   0.00000   0.00000       446\n",
      "           6    0.00000   0.00000   0.00000       479\n",
      "           7    0.10352   0.88716   0.18540       514\n",
      "           8    0.00000   0.00000   0.00000       487\n",
      "           9    0.00000   0.00000   0.00000       505\n",
      "\n",
      "    accuracy                        0.09980      5000\n",
      "   macro avg    0.01758   0.09630   0.02594      5000\n",
      "weighted avg    0.01884   0.09980   0.02745      5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       490\n",
      "           1    0.07227   0.07584   0.07401       567\n",
      "           2    0.00000   0.00000   0.00000       516\n",
      "           3    0.00000   0.00000   0.00000       505\n",
      "           4    0.00000   0.00000   0.00000       491\n",
      "           5    0.00000   0.00000   0.00000       446\n",
      "           6    0.00000   0.00000   0.00000       479\n",
      "           7    0.10352   0.88716   0.18540       514\n",
      "           8    0.00000   0.00000   0.00000       487\n",
      "           9    0.00000   0.00000   0.00000       505\n",
      "\n",
      "    accuracy                        0.09980      5000\n",
      "   macro avg    0.01758   0.09630   0.02594      5000\n",
      "weighted avg    0.01884   0.09980   0.02745      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adversarially trained model on clean test set\n",
    "test_pred = np.argmax(classifier.predict(x_test_s), axis=-1)\n",
    "print('Accuracy on clean testing data')\n",
    "print(classification_report(y_test_s_labels, test_pred, digits=5))\n",
    "print(classification_report(y_test_s_labels, np.argmax(trainer.trainer.predict(x_test_s), axis=-1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attacker object\n",
    "pgd = ProjectedGradientDescent(\n",
    "    classifier,\n",
    "    eps=0.3,\n",
    "    eps_step=0.01,\n",
    "    max_iter=40,\n",
    "    targeted=False,\n",
    "    num_random_init=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluate the adversarially trained model on fresh adversarial samples produced on the adversarially trained model\n",
    "x_test_pgd_new = pgd.generate(x_test_s[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        14\n",
      "           1    0.12371   0.92308   0.21818        13\n",
      "           2    0.00000   0.00000   0.00000        10\n",
      "           3    0.00000   0.00000   0.00000         8\n",
      "           4    0.00000   0.00000   0.00000        10\n",
      "           5    0.00000   0.00000   0.00000         7\n",
      "           6    0.00000   0.00000   0.00000        12\n",
      "           7    0.00000   0.00000   0.00000        10\n",
      "           8    0.00000   0.00000   0.00000         9\n",
      "           9    0.00000   0.00000   0.00000         7\n",
      "\n",
      "    accuracy                        0.12000       100\n",
      "   macro avg    0.01237   0.09231   0.02182       100\n",
      "weighted avg    0.01608   0.12000   0.02836       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pgd_new = np.argmax(classifier.predict(x_test_pgd_new), axis=-1)\n",
    "print(classification_report(y_test_s_labels[:100], labels_pgd_new, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
